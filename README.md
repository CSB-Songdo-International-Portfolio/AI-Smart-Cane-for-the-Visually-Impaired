# 제작 동기 및 목적

* 성 시각장애인이 무거운 짐을 끌고 차가 달리는 도로 위를 걸어 다닌 사례가 있다. 시각장애인은 한 운전자의 도움으로 길을 무사히 건널 수 있었다. 이렇게 매 순가 시각장애인들은 길거리에서 위험을 마주한다. 

* 시각장애인 이차용 씨는 길을 걷다 점자블록 위에 방치된 전동킥보드에 걸려 넘어져 앞니가 부러지는 큰 부상을 입었다​. 그는 평소 지팡이로 보도에 설치된 유도블록을 더듬어 보행하는데, 누군가 점자블록 위에 세워둔 공유 킥보드때문에 이를 인지하지 못하고 사고를 당했다​. 이처럼 인도 및 횡단보도 진입부에 방치된 전동킥보드나 불법주차 차량은 시각장애인에게 “지뢰”와 같아 걸려 넘어지거나 차도로 피하다 2차 사고로 이어질 수 있다.

* 국내 시각장애인은 1990년 1만 4000명에서 2019년 25만 3000명으로 약 25배 증가했으며, 고령화로 인해 앞으로도 시각장애 및 저시력 인구가 지속적으로 늘어날 전망이다, 그러므로 더욱 효과적인 이동 보조 기술의 필요성이 더욱 커지고 있다.

![image](https://github.com/user-attachments/assets/dbe928e9-082e-4e29-8f89-9e67e6e5a1d8)

# 작품 내용

핵심 기능
● 초음파 센서 및 카메라 센서를 통한 물체 인식
● 이미지 분류 모델을 활용한 종류별 사물 인식
● 음성 안내 기능

부가 기능
● GPS 안내 기능
● 자동 신고 기능
![image](https://github.com/user-attachments/assets/b4732a1e-a375-4a5c-b611-d4b294165586)
![image](https://github.com/user-attachments/assets/7e6702ee-401b-42da-bdef-edf0c258a795)


## 작동 흐름
* 사용자가 스마트 지팡이를 들고 걷기 시작하면, 지팡이에 장착된 초음파 센서가 실시간으로 
방의 물체와의 거리를 측정한다. 장애물이 10미터 이내에 감지되면, 카메라 센서가 자동으로
작동하여 주변 이미지를 촬영하고, 이 이미지는 인공지능 이미지 분류 시스템으로 전달된다.
이때 핵심적으로 사용되는 기술이 바로 합성곱 신경망과 YOLO 모델이다.

* CNN은 이미지 속에서 색상, 윤곽, 패턴 등 시각적 특징을 정밀하게 추출하고, 학습된 데이터를
기반으로 장애물이 어떤 종류인지 정확하게 분류한다. 반면, YOLO 는 더 나아가 이미지
속 객체의 종류와 정확한 위치까지 빠르게 탐지하여, 장애물이 어디에 있는지를 좌표 기반으로
실시간 분석한다. 이 두 기술의 결합으로, 지팡이는 단순히 '무언가 있다'고 알려주는 수준을
넘어, '앞쪽 1.5m에 공유 킥보드가 있습니다' 처럼 정확하고 구체적인 안내를 제공할 수 있다.

* 이러한 분석 결과는 음성 안내 시스템과 진동 피드백으로 사용자에게 즉시 전달된다. 예를 들 
어, YOLO 모델이 "전방 2미터 좌측에 사람"을 탐지하고, CNN이 그 대상을 ‘보행자’로 분류하면, 지팡이는 “앞에 사람이 있습니다. 주의하세요.”라고 음성으로 알려준다. 동시에 진동이 
울려 시각장애인은 정확한 위험 위치를 인지하고 안전하게 피할 수 있다.
